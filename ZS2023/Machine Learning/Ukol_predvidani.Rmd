
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

<hr>
## Ãškol 3.1
Nasimulujte z normÃ¡lnÃ­ho normovanÃ©ho rozdÄ›lenÃ­ 70 (vzÃ¡jemnÄ› nezÃ¡vislÃ½ch) hodnot pro
kaÅ¾dou z dvaceti nÃ­Å¾e uvaÅ¾ovanÃ½ch promÄ›nnÃ½ch. S vyuÅ¾itÃ­m tÄ›chto dat pomocÃ­ regresnÃ­ho
vztahu:

$$ğ‘¦_ğ‘– = ğ›½_1 ğ‘¥_{1,i} + ğ›½_2 ğ‘¥_{2,ğ‘–} + ... + ğ›½_{20} x_{20,i} + ğ‘¢_ğ‘–$$
nasimulujte hodnoty zÃ¡vislÃ© promÄ›nnÃ© $ğ‘¦$, kde parametry $ğ›½_1$ aÅ¾ $ğ›½_{10} = 1$ a parametry $ğ›½_{11}$ aÅ¾ $ğ›½_{20} = 0,1$. NÃ¡hodnÃ¡ chyba $u_i$ je normÃ¡lnÄ› rozdÄ›lenÃ¡ se stÅ™ednÃ­ hodnotou 0 a rozptylem 1.

Takto pÅ™ipravenÃ¡ data od tohoto okamÅ¾iku povaÅ¾ujte za danÃ¡.
DatovÃ½ soubor rozdÄ›lte na 50 a 20 pozorovÃ¡nÃ­. PrvnÃ­ch 50 pozorovÃ¡nÃ­ pouÅ¾ijte pro
trÃ©novÃ¡nÃ­ a kÅ™Ã­Å¾ovou validaci, zbylÃ½ch 20 jako testovacÃ­ mnoÅ¾inu pro odhad stÅ™ednÃ­
ÄtvercovÃ© (predikÄnÃ­) chyby. Pro predikci pouÅ¾ijte metodu nejmenÅ¡Ã­ch ÄtvercÅ¯, hÅ™ebenovou
regresi a LASSO regresi.

a. Pro optimÃ¡lnÃ­ volbu hyperparametrÅ¯ pouÅ¾ijte 5-nÃ¡sobnou kÅ™Ã­Å¾ovou validaci, pro niÅ¾
si napiÅ¡te vlastnÃ­ R kÃ³d (tj. nevyuÅ¾Ã­vejte dostupnÃ© funkce pro kÅ™Ã­Å¾ovou validaci
v existujÃ­cÃ­ch R balÃ­ÄcÃ­ch). K zÃ­skÃ¡nÃ­ samotnÃ© pÅ™edpovÄ›di dostupnÃ© R balÃ­Äky vyuÅ¾Ã­t
mÅ¯Å¾ete (viz napÅ™. glmnet, larsâ€¦). Pro uvaÅ¾ovanou mnoÅ¾inu hyperparametrÅ¯ vÅ¾dy uveÄte
velikost CV chyby (CV = cross-validation) a jejÃ­ smÄ›rodatnou odchylku. Vyberte
optimÃ¡lnÃ­ hodnotu hyperparametru.
b. VzÃ¡jemnÄ› srovnejte vÃ½sledky zÃ­skanÃ© pomocÃ­ jednotlivÃ½ch metod.
<hr>

```{r, warning=F, message=F}
library(matlib)
library(glmnet)
library(tidyverse)
library(mFilter)
```


```{r}
data <- as.data.frame(matrix(nrow = 70, ncol = 21))
colnames(data) <- c("X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10", "X11", "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19", "X20", "Y")

for(i in 1:20){
  data[,i] <- rnorm(70)
}

data$Y <- 10*data$X1 + 10*data$X2 + 10*data$X3 + 10*data$X4 + 10*data$X5 + 10*data$X6 + 10*data$X7 + 10*data$X8 + 10*data$X9 + 10*data$X10 + 0.1*data$X11 + 0.1*data$X12 + 0.1*data$X13 + 0.1*data$X14 + 0.1*data$X15 + 0.1*data$X16 + 0.1*data$X17 + 0.1*data$X18 + 0.1*data$X19 + 0.1*data$X20 + rnorm(1)
data$Rozdeleni <- rep(1:5, 14)
```

```{r}
#RozdÄ›lenÃ­ dat na trÃ©novacÃ­ a testovacÃ­
data_train <- data[1:50,]
data_test <- data[51:70,]

X <- cbind(1, as.matrix(data_train[,1:20]))
y <- as.matrix(data_train[,21])
```

```{r}
#Funkce pro vÃ½poÄet stÅ™ednÃ­ ÄtvercovÃ© chyby

MSE <- function(beta, X, y){
  n <- nrow(X)
  y_predikce <- as.matrix(X) %*% beta
 
  MSE <- 1/n * sum((y_predikce - y)^2)
  return(MSE)
}
```

```{r}
#Funkce pro hledÃ¡nÃ­ nejlepÅ¡Ã­ lambdy

nejlepsiLambda <- function(data_test_l, data_train_l, typ){
  lambda_values <- seq(10, 0.5, length = 100)
  best_error <- Inf
  best_lambda <- NULL
  
  for(lambda in lambda_values){
    model <- glmnet(as.matrix(data_train_l[,1:20]), y = data_train_l[,21], aplha = typ, lambda = lambda)
    
    beta_lambda <- as.vector(coef(model))
    X_lambda <- as.matrix(cbind(1, data_test_l[,1:20]))
    predictions <- X_lambda %*% beta_lambda
    error <- mean((predictions - data_test_l[,21])^2)
    
    if(error < best_error){
      best_error <- error
      best_lambda <- lambda
    }
  }
  
  lambdaCV <- c("BestLambda" = best_lambda, "BestError" = best_error)
  return(lambdaCV)
}
```


### Metoda nejmenÅ¡Ã­ch ÄtvercÅ¯


```{r}
beta_OLS <- as.vector(inv(t(X) %*% X) %*% t(X) %*% y)
nazvy <- c()

for(i in 1:21){
  nazvy[i] <- paste("b", (i-1), sep = "")
}

names(beta_OLS) <- nazvy
beta_OLS
```

```{r}
MSE_OLS <- MSE(beta_OLS, cbind(1,data_test[,1:20]), data_test[,21])
```

### HÅ™ebenovÃ¡ regrese


```{r}
#Volba lambdy
lambdaCV_hreb <- as.data.frame(matrix(nrow = 5, ncol = 2))
colnames(lambdaCV_hreb) = c("Best_lambda", "Best_error")

for(i in 1:5){
  data_test_l_hreb <- data_train[data_train$Rozdeleni == i,]
  data_train_l_hreb <- data_train[data_train$Rozdeleni != i,]
  
  lambdaCV_hreb[i,] <- nejlepsiLambda(data_test_l_hreb, data_train_l_hreb, 0)
}

lambda_hreb <- mean(lambdaCV_hreb$Best_lambda)
c("NejlepÅ¡Ã­ lambda" = lambda_hreb, "NejlepÅ¡Ã­ error" = mean(lambdaCV_hreb$Best_error))
```


```{r}
#VÃ½poÄet parametrÅ¯
beta_hreb <- as.vector(inv(t(X) %*% X + diag(lambda_hreb, ncol(X))) %*% t(X) %*% y)

names(beta_hreb) <- nazvy
beta_hreb
```

```{r}
MSE_hreb <- MSE(beta_hreb, cbind(1,data_test[,1:20]), data_test[,21])
```

### LASSO

```{r}
#Volba lambdy
lambdaCV_lasso <- as.data.frame(matrix(nrow = 5, ncol = 2))
colnames(lambdaCV_lasso) = c("Best_lambda", "Best_error")

for(i in 1:5){
  data_test_l_lasso <- data_train[data_train$Rozdeleni == i,]
  data_train_l_lasso <- data_train[data_train$Rozdeleni != i,]
  
  lambdaCV_lasso[i,] <- nejlepsiLambda(data_test_l_lasso, data_train_l_lasso, 1)
}

lambda_lasso <- mean(lambdaCV_lasso$Best_lambda)
c("NejlepÅ¡Ã­ lambda" = lambda_lasso, "NejlepÅ¡Ã­ error" = mean(lambdaCV_lasso$Best_error))
```

```{r}
lasso_model <- glmnet(X[,2:21], y, alpha = 1, lambda = lambda_lasso)
beta_lasso <- as.vector(coef(lasso_model))

names(beta_lasso) <- nazvy
beta_lasso
```

```{r}
MSE_lasso <- MSE(beta_lasso, cbind(1,data_test[,1:20]), data_test[,21])
```

#### PorovnÃ¡nÃ­ ÄtvercovÃ½ch chyb predikce

```{r}
c("MSE - OLS" = MSE_OLS, "MSE - hÅ™ebenovÃ¡ r." = MSE_hreb, "MSE - LASSO" = MSE_lasso)
```

<hr>

## Ãškol 3.2

Sestrojte model pro pÅ™edpovÄ›Ä sezonnÄ› oÄiÅ¡tÄ›nÃ©ho hrubÃ©ho disponibilnÃ­ho dÅ¯chodu domÃ¡cnostÃ­ v ÄŒR na jedno aÅ¾ ÄtyÅ™i ÄtvrtletÃ­ dopÅ™edu. V rÃ¡mci tohoto modelu vhodnÃ½m zpÅ¯sobem vyuÅ¾ijte ML algoritmÅ¯. 

Pro trÃ©novÃ¡nÃ­ algoritmÅ¯ pouÅ¾ijte obdobÃ­ 1Q 1999 â€“ 4Q 2017. PÅ™edpovÄ›di proveÄte pro 1Qâ€“4Q 2018, 1Qâ€“4Q 2019 a 1Qâ€“4Q 2020 (pro pÅ™edpovÄ›Ä na 1Qâ€“4Q 2019 pouÅ¾ijte data aÅ¾ do 4Q 2018, ale data po 4Q 2017 jiÅ¾ nevyuÅ¾Ã­vejte pro trÃ©novÃ¡nÃ­ algoritmÅ¯, analogicky postupujte i u pÅ™edpovÄ›dÃ­ na obdobÃ­ 1Qâ€“
4Q 2020).

<hr>

```{r}
data_HDD <- read.csv("HDD.csv")[1:88,]
hp_SO <- hpfilter(data_HDD$HDD,freq=10,type="frequency", drift=TRUE)
data_HDD$HDD_SO <- data_HDD$HDD - as.vector(hp_SO$cycle)
```

```{r}
data_HDD_train_2018 <- data_HDD[1:76,]
data_HDD_test_2018 <- data_HDD[77:80,]

hp_2018 <- hpfilter(data_HDD_train_2018$HDD,freq=10,type="frequency", drift=TRUE)
data_HDD_train_2018$trend <- hp_2018$trend
data_HDD_train_2018$t <- c(1:76)
data_HDD_train_2018$t2 <- data_HDD_train_2018$t^2
data_HDD_train_2018$t3 <- data_HDD_train_2018$t^3

model_trend <- lm(trend ~ t + t2 + t3, data_HDD_train_2018)
plot(data_HDD_train_2018$trend, type = "l")
lines(model_trend$fitted.values, col = "red")

model_hdd <- lm(HDD_SO ~ t + trend, data_HDD_train_2018)
plot(data_HDD_train_2018$HDD_SO, type = "l")
lines(model_hdd$fitted.values, col = "red")

t <- as.data.frame(rbind(c(77, 77^2, 77^3), c(78, 78^2, 78^3), c(79, 79^2, 79^3), c(80, 80^2, 80^3)))
colnames(t) <- c("t", "t2", "t3")
predpoved_trend <- predict(model_trend, newdata = cbind(1, t))

hdd_predpoved_data <- as.data.frame(cbind(1, "trend" = predpoved_trend, "t" = c(77:80)))
predpoved_hdd <- predict(model_hdd, newdata = hdd_predpoved_data)
rbind(predpoved_hdd, data_HDD_test_2018$HDD_SO)

c("R-squared" = cor(predpoved_hdd, data_HDD_test_2018$HDD_SO)^2)
```

```{r}
data_HDD_train_2019 <- data_HDD[1:80,]
data_HDD_test_2019 <- data_HDD[81:84,]

hp_2019 <- hpfilter(data_HDD_train_2019$HDD,freq=10,type="frequency", drift=TRUE)
data_HDD_train_2019$trend <- hp_2019$trend
data_HDD_train_2019$t <- c(1:80)
data_HDD_train_2019$t2 <- data_HDD_train_2019$t^2
data_HDD_train_2019$t3 <- data_HDD_train_2019$t^3

model_trend_2019 <- lm(trend ~ t + t2 + t3, data_HDD_train_2019)
plot(data_HDD_train_2019$trend, type = "l")
lines(model_trend_2019$fitted.values, col = "red")

model_hdd_2019 <- lm(HDD_SO ~ t + trend, data_HDD_train_2019)
plot(data_HDD_train_2019$HDD_SO, type = "l")
lines(model_hdd_2019$fitted.values, col = "red")

t_2019 <- as.data.frame(rbind(c(81, 81^2, 81^3), c(82, 82^2, 82^3), c(83, 83^2, 83^3), c(84, 84^2, 84^3)))
colnames(t_2019) <- c("t", "t2", "t3")
predpoved_trend_2019 <- predict(model_trend_2019, newdata = cbind(1, t_2019))

hdd_predpoved_data_2019 <- as.data.frame(cbind(1, "trend" = predpoved_trend_2019, "t" = c(81:84)))
predpoved_hdd_2019 <- predict(model_hdd_2019, newdata = hdd_predpoved_data_2019)

rbind(predpoved_hdd_2019, data_HDD_test_2019$HDD_SO)
c("R-squared" = cor(predpoved_hdd_2019, data_HDD_test_2019$HDD_SO)^2)
```

```{r}
data_HDD_train_2020 <- data_HDD[1:84,]
data_HDD_test_2020 <- data_HDD[85:88,]

hp_2020 <- hpfilter(data_HDD_train_2020$HDD,freq=10,type="frequency", drift=TRUE)
data_HDD_train_2020$trend <- hp_2020$trend
data_HDD_train_2020$t <- c(1:84)
data_HDD_train_2020$t2 <- data_HDD_train_2020$t^2
data_HDD_train_2020$t3 <- data_HDD_train_2020$t^3

model_trend_2020 <- lm(trend ~ t + t2 + t3, data_HDD_train_2020)
plot(data_HDD_train_2020$trend, type = "l")
lines(model_trend_2020$fitted.values, col = "red")

model_hdd_2020 <- lm(HDD_SO ~ t + trend, data_HDD_train_2020)
plot(data_HDD_train_2020$HDD_SO, type = "l")
lines(model_hdd_2020$fitted.values, col = "red")

t_2020 <- as.data.frame(rbind(c(85, 85^2, 85^3), c(86, 86^2, 86^3), c(87, 87^2, 87^3), c(88, 88^2, 88^3)))
colnames(t_2020) <- c("t", "t2", "t3")
predpoved_trend_2020 <- predict(model_trend_2020, newdata = cbind(1, t_2020))

hdd_predpoved_data_2020 <- as.data.frame(cbind(1, "trend" = predpoved_trend_2020, "t" = c(85:88)))
predpoved_hdd_2020 <- predict(model_hdd_2020, newdata = hdd_predpoved_data_2020)
rbind(predpoved_hdd_2020, data_HDD_test_2020$HDD_SO)

c("R-squared" = cor(predpoved_hdd_2020, data_HDD_test_2020$HDD_SO)^2)
```


<hr>

## Ãškol 3.3

Sestrojte model pro pÅ™edpovÄ›Ä poÄtu Å¾ivÄ› narozenÃ½ch dÄ›tÃ­ v ÄŒR. Model by mÄ›l bÃ½t schopen pÅ™edpovÃ­dat poÄet Å¾ivÄ› narozenÃ½ch dÄ›tÃ­ na 5 let dopÅ™edu â€“ dÅ¯vodem pro pÅ™edpovÄ›Ä je potÅ™eba plÃ¡novÃ¡nÃ­ kapacity Å¡kolek a moÅ¾nost vÄasnÃ© reakce na jejich pÅ™Ã­padnÃ½ nedostatek/nadbytek. HlavnÃ­ dÅ¯raz v tomto Ãºkolu je kladen na detailnÃ­ popis zÃ¡kladnÃ­ logiky a struktury modelu plus hlavnÃ­ konceptuÃ¡lnÃ­ kroky pÅ™i zÃ­skÃ¡vÃ¡nÃ­ pÅ™edpovÄ›di.

<hr>

```{r}
data_ <- read.csv("Data_ML_narozeni.csv", sep = ";")
colnames(data_) <- data_[1,]

data_narozeni <- tibble(
  Vek_matky = as.numeric(data_$Prum_vek_matky[2:31]),
  Rozvodovost = as.numeric(data_$Rozvodovost[2:31]),
  HDP = as.numeric(data_$HDP[2:31]),
  Nezamestnanost = as.numeric(data_$Nezamestnanost[2:31]),
  Plodnost = as.numeric(data_$Uhrnna_plodnost[2:31]),
  Pocet_narozenych = as.numeric(data_$Zive_narozeni[2:31])
)
data_narozeni$ZmenaHDP <- 1

for(i in 2:30){
  data_narozeni[i,7] <- data_narozeni$HDP[i]/data_narozeni$HDP[(i-1)]
}

#VytvoÅ™enÃ­ modelu
model_narozeni <- lm(Pocet_narozenych ~ Vek_matky + Rozvodovost + ZmenaHDP + Nezamestnanost + Plodnost, data = data_narozeni)
coef(model_narozeni)

plot(data_narozeni$Pocet_narozenych, type = "l")
lines(model_narozeni$fitted.values, col = "red")
```


```{r}
data_narozeni$t <- c(1:30)
data_narozeni$t2 <- (data_narozeni$t)^2


#ModelovÃ¡nÃ­ pÅ™edpovÄ›di vÄ›ku matky
model_vekMatky <- lm(Vek_matky ~ t + t2, data_narozeni)
predpoved_vekMatky <- c()
for(i in 31:35){
  predpoved_vekMatky[(i-30)] <- sum(model_vekMatky$coefficients * c(1, i, i^2))
}

plot(data_narozeni$Vek_matky, type = "l")
lines(model_vekMatky$fitted.values, col = "red")


#ModelovÃ¡nÃ­ pÅ™edpovÄ›di Rozvodovosti
model_Rozvodovost <- lm(Rozvodovost ~ t + t2, data_narozeni)
predpoved_Rozvodovost <- c()
for(i in 31:35){
  predpoved_Rozvodovost[(i-30)] <- sum(model_Rozvodovost$coefficients * c(1, i, i^2))
}

plot(data_narozeni$Rozvodovost, type = "l")
lines(model_Rozvodovost$fitted.values, col = "red")

hp_Rozvodovost <- hpfilter(data_narozeni$Rozvodovost,freq=10,type="frequency", drift=TRUE)
data_narozeni$HP_Rozvodovost <- hp_Rozvodovost$trend

#ModelovÃ¡nÃ­ pÅ™edpovÄ›di HDP -> pÅ™edpoklÃ¡dÃ¡me, Å¾e steady-state je rÅ¯st o prÅ¯mÄ›r
predpoved_zmenaHDP <- rep(mean(data_narozeni$ZmenaHDP), 5)
predpoved_zmenaHDP2 <- rep(2, 5) #steady-state podle pÅ™edpovÄ›di

#ModelovÃ¡nÃ­ pÅ™edpovÄ›di nezamÄ›stnanosti
model_nezamestnanost <- lm(Nezamestnanost ~ t, data_narozeni)
predpoved_Nezamestnanost <- c()
for(i in 31:35){
  predpoved_Nezamestnanost[(i-30)] <- sum(model_nezamestnanost$coefficients * c(1, i))
}

plot(data_narozeni$Nezamestnanost, type = "l")
lines(model_nezamestnanost$fitted.values, col = "red")


#ModelovÃ¡nÃ­ pÅ™edpovÄ›di plodnosti
model_Plodnost <- lm(Plodnost ~ t, data_narozeni)
plot(data_narozeni$Plodnost, type = "l")
lines(model_Plodnost$fitted.values, col = "red")

predpoved_Plodnost <- c()
for(i in 31:35){
  predpoved_Plodnost[(i-30)] <- sum(model_Plodnost$coefficients * c(1, i))
}

predpoved <- as.data.frame(cbind("Vek_matky" = predpoved_vekMatky, "Rozvodovost" = predpoved_Rozvodovost, "ZmenaHDP" = predpoved_zmenaHDP, "Nezamestnanost" = predpoved_Nezamestnanost, "Plodnost" = predpoved_Plodnost))
predpoved2 <- as.data.frame(cbind("Vek_matky" = predpoved_vekMatky, "Rozvodovost" = predpoved_Rozvodovost, "ZmenaHDP" = predpoved_zmenaHDP2, "Nezamestnanost" = predpoved_Nezamestnanost, "Plodnost" = predpoved_Plodnost))
```

```{r}
predikce_poctuDeti <- as.data.frame(matrix(nrow = 6, ncol = 0))
predikce_poctuDeti$Roky <- c(2022:2027)
predikce_poctuDeti$Pocet <- c(data_narozeni$Pocet_narozenych[30],predict(model_narozeni, newdata = predpoved))

predikce_poctuDeti2 <- as.data.frame(matrix(nrow = 6, ncol = 0))
predikce_poctuDeti2$Roky <- c(2022:2027)
predikce_poctuDeti2$Pocet <- c(data_narozeni$Pocet_narozenych[30],predict(model_narozeni, newdata = predpoved2))

ggplot() +
  geom_line(data = data_narozeni, aes(x = c(1993:2022), y = Pocet_narozenych)) +
  geom_line(data = predikce_poctuDeti, aes(x = Roky, y = Pocet), color = "red") +
  geom_line(data = predikce_poctuDeti2, aes(x = Roky, y = Pocet), color = "darkgreen") +
  xlab("ObdobÃ­") + ylab("PoÄet narozenÃ½ch dÄ›tÃ­")
```
















